{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiYSoZYZPsPf",
        "outputId": "79df36e8-4ac8-4f54-fa0c-8fe5904162b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: gpt2 in /usr/local/lib/python3.10/dist-packages (0.0.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (0.15.0)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (4.9.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text) (3.2.2)\n",
            "Requirement already satisfied: matplotlib-venn in /usr/local/lib/python3.10/dist-packages (0.11.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from matplotlib-venn) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from matplotlib-venn) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from matplotlib-venn) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->matplotlib-venn) (1.16.0)\n",
            "--2023-12-21 06:43:24--  https://storage.googleapis.com/bert_models/2018_11_03/uncased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.115.207, 172.253.122.207, 172.253.63.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.115.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 403 Forbidden\n",
            "2023-12-21 06:43:24 ERROR 403: Forbidden.\n",
            "\n",
            "unzip:  cannot find or open uncased_L-12_H-768_A-12.zip, uncased_L-12_H-768_A-12.zip.zip or uncased_L-12_H-768_A-12.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "# !pip install openai==1.0.0\n",
        "# !pip install --upgrade openai\n",
        "!pip install openai==0.28\n",
        "\n",
        "!pip install gpt2\n",
        "\n",
        "!pip install transformers\n",
        "!pip install tensorflow_text\n",
        "!pip install matplotlib-venn\n",
        "\n",
        "!wget https://storage.googleapis.com/bert_models/2018_11_03/uncased_L-12_H-768_A-12.zip\n",
        "!unzip uncased_L-12_H-768_A-12.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### coment : The BLEU (Bilingual Evaluation Understudy) score is a metric commonly used for evaluating the quality of machine-generated text, such as translations.\n",
        "### It measures the similarity between a generated response and one or more reference responses. The higher the BLEU score, the better the match between the generated\n",
        "### response and the reference.\n",
        "\n",
        "### The BLEU score is usually between 0 and 1, where 1 indicates a perfect match. Depending on your specific requirements, you might choose to scale or normalize the\n",
        "### BLEU score to fit within a certain range.\n",
        "\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "def calculate_bleu(generated_response, reference_response):\n",
        "    # Convert the candidate and reference to lists of tokens\n",
        "    candidate_tokens = generated_response.split()\n",
        "    reference_tokens = reference_response.split()\n",
        "\n",
        "    # Calculate BLEU score using NLTK's sentence_bleu\n",
        "    bleu_score = sentence_bleu([reference_tokens], candidate_tokens)\n",
        "\n",
        "    return bleu_score\n"
      ],
      "metadata": {
        "id": "zlcFfeWLPs43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### coment : For a genetic algorithm that involves a Language Model (LLM) and uses a fitness function, you can utilize pre-trained language models provided\n",
        "### by various NLP (Natural Language Processing) libraries. These libraries often include pre-trained models that can generate language representations and\n",
        "### compute perplexity scores. Here are a few popular NLP libraries and their associated pre-trained language models :\n",
        "### Models: GPT-2, GPT-3, BERT, T5, etc.\n",
        "### Usage: You can use the Hugging Face Transformers library to load pre-trained models and calculate perplexity. Example code for GPT-2:\n",
        "\n",
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "def calculate_perplexity1(generated_response):\n",
        "\n",
        "    model_name = \"gpt2\"  # Replace with the desired model\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "    # Calculate perplexity (replace with your text and input IDs)\n",
        "    input_ids = tokenizer.encode(generated_response, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate predictions from the model\n",
        "    with torch.no_grad():\n",
        "         logits = model(input_ids)[0]\n",
        "\n",
        "    # Calculate cross-entropy loss\n",
        "    loss = torch.nn.functional.cross_entropy(logits.view(-1, logits.shape[-1]), input_ids.view(-1))\n",
        "\n",
        "    # Calculate perplexity from the loss\n",
        "    perplexity1 = torch.exp(loss)\n",
        "\n",
        "    perplexity_scalar = perplexity1.item()\n",
        "    perplexity_scalar = round(perplexity_scalar,2)\n",
        "\n",
        "    return perplexity_scalar\n"
      ],
      "metadata": {
        "id": "8kTs9fP5TqO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def list_length_responses(list_responses):\n",
        "\n",
        "    lengths_list = [len(item) for item in list_responses]\n",
        "\n",
        "    return lengths_list"
      ],
      "metadata": {
        "id": "Qkfx_NE-Gaoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### To include the criteria of words related to the main subject asked in the question into the fitness function for genetic algorithms with a Language Model (LLM),\n",
        "### you can use semantic similarity or keyword matching techniques. This aims to ensure that the generated response is relevant to the main subject of the question.\n",
        "\n",
        "### Keyword Matching:\n",
        "\n",
        "# Identify key terms or keywords in the question that represent the main subject.\n",
        "# Check whether these keywords are present in the generated response.\n",
        "# Assign a score based on the presence or absence of these keywords.\n",
        "# Semantic Similarity:\n",
        "\n",
        "# Use a pre-trained word embedding model or transformer-based model to embed the question and the generated response.\n",
        "# Calculate the semantic similarity between the embeddings.\n",
        "# Assign a score based on the similarity.\n",
        "\n",
        "i = 1\n",
        "a_size_vec = []\n",
        "\n",
        "def fitness_function4(generated_response, reference_response, perplexity, user_input):\n",
        "    # Use BLEU score to measure similarity to reference response\n",
        "    bleu_score = calculate_bleu(generated_response, reference_response)\n",
        "\n",
        "    # Penalize higher perplexity for less coherent responses\n",
        "    perplexity_penalty = 1 / perplexity\n",
        "\n",
        "### -----------------------------------------------------------------------------------------------------\n",
        "\n",
        "    min_val = min(lengths_list)\n",
        "    max_val = max(lengths_list)\n",
        "    answer_size = len(generated_response)\n",
        "    answer_size_score = (answer_size - min_val) / (max_val - min_val)\n",
        "    answer_size_score = max(0, min(1, answer_size_score))\n",
        "\n",
        "### -----------------------------------------------------------------------------------------------------\n",
        "\n",
        "    # Keyword matching to check if important words are present in the response\n",
        "\n",
        "    question = user_input\n",
        "\n",
        "    question_keywords = set(question.lower().split())\n",
        "\n",
        "    # Check how many keywords are present in the generated response\n",
        "    matching_keywords = [keyword for keyword in question_keywords if keyword in generated_response.lower()]\n",
        "\n",
        "    # Calculate a relevance score based on the number of matching keywords\n",
        "    relevance_score = [(len(matching_keywords) / len(question_keywords)) if len(question_keywords) > 0 else 0.0]\n",
        "    relevance_score = relevance_score[0]\n",
        "\n",
        "    # BLEU-score = evaluating the quality of machine-generated text, such as translation.\n",
        "    # perplexity = quantify how well the model predicts the next word in a sequence.\n",
        "    # answer_size = how big is the answer is better\n",
        "    # relevance_score = words related to the main subject asked in the question\n",
        "\n",
        "     # Combine metrics with weighted averages\n",
        "    fitness_score = 0.4 * bleu_score + 0.3 * perplexity_penalty + 0.1 * answer_size_score + 0.2 * relevance_score  # Adjust the weight based on the importance you give to answer size\n",
        "    # Adjust the weight based on the importance you give to keyword matching\n",
        "\n",
        "    return fitness_score\n"
      ],
      "metadata": {
        "id": "Q7RJRmHPag4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wNXj8O51ag7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "79pu37NtahJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 1 : GIVE THE ANSWER GENERATED BY THE GENETIC ALGORITHM / GIVE THE REFERENCE RESPONSE\n",
        "\n",
        "user_input = 'give me a deep explaination about fitness funtion for genetic algorithms LLM' ### DIGITE AQUI UMA PERGUNTA"
      ],
      "metadata": {
        "id": "lgfgitruPtBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generated_response = connect_user_input_python_chatgp(user_input)\n",
        "# generated_response\n",
        "\n",
        "\n",
        "generated_response1 = 'Certainly! In the context of genetic algorithms (GAs) and machine learning, the fitness function plays a crucial role in guiding the evolution of solutions toward an optimal or desired outcome. Lets break down the concept of a fitness function in the context of machine learning, particularly in the context of Large Language Models (LLMs) and genetic algorithms.'\n",
        "generated_response2 = 'When applying genetic algorithms (GAs) to the training or optimization of Large Language Models (LLMs), the fitness function serves as a crucial component for evaluating the quality of potential solutions (individual models or configurations) within the population. The goal is to guide the evolutionary process toward generating LLMs that excel in language-related tasks. Heres a more detailed explanation of the fitness function in the context of genetic algorithms for LLMs:'\n",
        "generated_response3 = 'Oi tudo bem! hoje terá competição de futebol as 13h!'\n",
        "\n",
        "\n",
        "list_responses = [generated_response1, generated_response2, generated_response3]\n",
        "\n",
        "lengths_list = list_length_responses(list_responses)\n",
        "lengths_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oTt78RhsEg8",
        "outputId": "15264093-1395-406d-d3d8-b17954571442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[363, 477, 52]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_score = calculate_bleu(generated_response, reference_response)\n",
        "bleu_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6R0hlCubIfbS",
        "outputId": "e865c780-78bb-4af2-fec8-c806d74d918d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_val = min(lengths_list)\n",
        "max_val = max(lengths_list)\n",
        "answer_size = len(generated_response)\n",
        "answer_size_score = (answer_size - min_val) / (max_val - min_val)\n",
        "answer_size_score = max(0, min(1, answer_size_score))\n",
        "answer_size_score\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI_k7HBYIop0",
        "outputId": "5344013a-b89d-4a99-9d77-e68308ef13b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = user_input\n",
        "\n",
        "question_keywords = set(question.lower().split())\n",
        "\n",
        "# Check how many keywords are present in the generated response\n",
        "matching_keywords = [keyword for keyword in question_keywords if keyword in generated_response.lower()]\n",
        "\n",
        "# Calculate a relevance score based on the number of matching keywords\n",
        "relevance_score = [(len(matching_keywords) / len(question_keywords)) if len(question_keywords) > 0 else 0.0]\n",
        "relevance_score = relevance_score[0]\n",
        "relevance_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRZmq0mRI4Ba",
        "outputId": "00ab03b0-4c5d-45f4-e548-755c19c7d187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08333333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_response = generated_response3\n",
        "reference_response = generated_response3\n",
        "candidate_response = generated_response\n",
        "\n",
        "### --------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "### STEP 2 : CALCULATE PERPLEXITY\n",
        "\n",
        "perplexity1 = calculate_perplexity1(generated_response)\n",
        "print(perplexity1)"
      ],
      "metadata": {
        "id": "5d5ugtFFo28d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27790a9f-a813-4cb2-ed6f-c1256a109b05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3704.68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### --------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "fitness_function4 = fitness_function4(generated_response, reference_response, perplexity1, user_input)\n",
        "fitness_function4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hxJmtgWvQhX",
        "outputId": "1fe17a9a-ebca-4ec7-ba83-31b339d6f92b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.41674764532069347"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jKb-GqelvQnw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}